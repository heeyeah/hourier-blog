---
title: "Claude Code로 나만의 AI 팀 만들기 — 에이전트 설계서가 코드보다 중요한 이유"
description: "Claude Code로 AI 에이전트를 만들어본 경험을 바탕으로, 에이전트 설계서가 결과물 퀄리티를 결정하는 이유와 핵심 작성법을 정리했다."
category: "AI"
tags: ["Claude Code", "AI 에이전트", "에이전트 설계서", "자동화", "CLAUDE.md"]
date: "2026-02-22"
slug: "claude-code-agent-design"
source: "https://youtu.be/C6xlOsQFyOQ"
---

## Claude Code로 나만의 AI 팀 만들기 — 에이전트 설계서가 코드보다 중요한 이유

최근에 `Claude Code`로 에이전트를 직접 만들어보면서 느낀 게 있다. 코딩 실력이 아니라 **내가 뭘 하고 싶은지를 얼마나 잘 정리할 수 있는가**가 결과물의 퀄리티를 결정한다는 것.

처음에는 나도 반신반의했다. 코드를 안 짜고 에이전트를 만든다고? ~~그게 말이 되나~~ 근데 실제로 해보니까 진짜 핵심은 코드가 아니었다. 설계서, 그러니까 내가 이 에이전트에게 시킬 일을 얼마나 구체적으로 적어놓느냐가 전부였다.

이 주제로 정리하게 된 계기는 유튜브에서 본 영상 하나 때문이다. "코딩 1도 모르는 직장인을 위한 Claude Code 시작 가이드"라는 제목인데, 여기서 에이전트 설계서 작성법을 5단계로 풀어놓은 게 인상적이었다. 영상을 보면서 내가 실제로 에이전트를 만들면서 겪은 경험과 겹치는 부분이 많아서, 이걸 내 관점으로 정리해보고자 한다.

그리고 솔직히 말하면, 에이전트를 아직 안 만들어본 사람한테 **꼭 한번 만들어보라고 말하고 싶은 마음**이 크다😊

---

## Claude Code는 뭐가 다른가

우리가 흔히 쓰는 `ChatGPT`나 `Claude`는 질문하면 답변해주는 형태다. "이거 어떻게 해?" → "이렇게 하세요" 하는 식.

근데 `Claude Code`는 좀 다르다. 질문에 답하는 게 아니라 **직접 실행하는 팀원**에 가깝다.

파일을 만들고, 코드를 수정하고, 터미널 명령어를 실행하고, 결과를 확인하고. 이걸 사람이 하나하나 시키는 게 아니라, 설계서(= `CLAUDE.md` 같은 문서)를 읽고 스스로 판단해서 움직인다.

그래서 이 "팀원"한테 일을 잘 시키려면 뭐가 필요할까? 코딩 실력? 아니다. **업무 지시를 잘 하는 능력**이다.

> 좋은 결과물에 대한 성공 기준을 가지고 있는 사람이 좋은 에이전트를 만든다.

이 말이 핵심인 것 같다.

---

## 에이전트 설계서 작성법: 5단계 + 핵심 3요소

### 에이전트 만들기 5단계

영상에서 소개된 프레임워크를 참고했는데, 내가 실제로 `Claude Code` 에이전트를 만들면서 겪은 흐름과 겹치는 부분이 많아서 내 경험에 맞게 재구성해봤다.

- **프로젝트 생성**: 폴더 구조 잡기, 작업 범위 정하기
- **설계서 작성**: 에이전트가 뭘 해야 하는지 문서로 정리
- **설계 검토**: Claude한테 설계서를 보여주고 빠진 부분 피드백 받기
- **세팅**: 필요한 스크립트, 도구, 파일 구조 갖추기
- **실행 & 개선**: 돌려보고 안 되는 부분 고치기 (이게 반복)

여기서 가장 시간이 많이 드는 건 2번, 설계서 작성이다. ~~코드 짜는 것보다 이게 더 오래 걸린다~~

근데 생각해보면 당연하다. 에이전트한테 일을 시키려면 내가 먼저 그 일을 완벽하게 이해하고 있어야 하니까.

### 설계서의 핵심 3요소: What, Why, How

설계서를 쓸 때 중요한 프레임워크가 있다. 뭘 적어야 하는지 막막할 때 이 세 가지를 기준으로 잡으면 돼요.

**What — 상세 절차**

에이전트가 실행할 작업의 순서와 내용을 적는다. "자막을 추출한다"가 아니라 **"어떤 스크립트를 실행해서, 어떤 형식으로, 어디에 저장하는지"**까지 적어야 한다.

내가 실제로 `Claude Code`의 `CLAUDE.md`에 적은 예시를 보면:

```markdown
### STEP 1: 자막 추출
스크립트를 실행하여 자막을 추출한다:
python .claude/skills/youtube-transcript/scripts/extract_transcript.py <YouTube_URL> output/transcripts

- 성공 기준: 자막 파일 생성, 최소 500자 이상
- 자막 우선순위: 한국어 수동 → 한국어 자동 생성 → 영어 자막
- 실패 시: 자동 재시도 1회 → 실패 시 사용자에게 알림 후 중단
```

이 정도로 구체적이어야 에이전트가 헤매지 않는다.

**Why — 의도**

왜 이 작업을 하는지, 이 단계에서 기대하는 결과가 뭔지를 적는다. 단순히 절차만 나열하면 에이전트가 예외 상황에서 판단을 못 한다. 의도를 알아야 유연하게 대처할 수 있다.

**How — 역할 분담과 도구**

핵심 원칙은 간단하다. **`LLM`이 할 일과 코드 스크립트가 할 일을 명확하게 나누는 것**이다. 판단이 필요한 건 `LLM`에게, 정확하고 반복적인 작업은 코드에게 맡긴다. 이 구분이 모호하면 에이전트의 퀄리티가 확 떨어진다. (바로 다음 섹션에서 구체적인 예시를 다룬다.)

---

## Claude Code 에이전트 설계 실전 팁

### LLM vs 코드 스크립트 역할 분담

이게 에이전트 설계에서 정말 중요한 부분이다.

`LLM`(= Claude 같은 언어 모델)은 **판단, 요약, 비정형 텍스트 처리**에 강하다. 반면 코드 스크립트는 **정확하고 반복적인 작업**에 강하다.

예를 들면:

| 작업 | 누가 할까 |
|------|-----------|
| 자막에서 핵심 내용 요약 | `LLM` |
| YouTube에서 자막 데이터 추출 | 코드 스크립트 (`yt-dlp`) |
| 글감에서 블로그 초고 작성 | `LLM` |
| 파일을 특정 경로에 저장 | 코드 스크립트 |
| 두 피드백 간 충돌 감지 | `LLM` |
| `JSON` 스키마 검증 | 코드 스크립트 |

내가 처음에 했던 실수가 뭐냐면, `LLM`한테 파일 저장까지 시킨 거다. "이 내용을 `output/ideas/` 폴더에 마크다운으로 저장해"라고. ~~될 때도 있고 안 될 때도 있어서 멘탈이ㅋㅋ~~

결국 파일 저장은 `Python` 스크립트(`save_idea.py`)로 분리했더니 안정적으로 동작했다. 정확성이 필요한 건 코드에, 판단이 필요한 건 `LLM`에. 이 원칙만 지키면 `Claude Code` 에이전트의 안정성이 확 올라간다.

### `Human-in-the-Loop`로 퀄리티 높이기

에이전트를 처음 만들 때 욕심이 생긴다. 전부 자동화하고 싶은 거다. URL만 넣으면 블로그 포스팅까지 뚝딱 나오는 그런 거.

근데 실제로 해보면, **사람이 중간에 개입하는 포인트**를 넣는 게 결과물 퀄리티가 훨씬 좋다.

내 파이프라인에서는 `Human-in-the-Loop` 포인트를 3곳에 넣었다:

- **글감 선택**: 에이전트가 제안한 글감 중에서 내가 고름
- **스타일/SEO 피드백 충돌 시**: 어느 쪽을 우선할지 내가 결정
- **최종 검토**: 발행 전에 내가 직접 확인

완전 자동화를 하면 "그럭저럭 괜찮은" 글이 나온다. 근데 `Human-in-the-Loop`를 넣으면 "내 글" 같은 게 나온다. 이 차이가 크다.

특히 글감 선택 단계에서 **취지문**(= 이 글을 어떤 관점으로 쓸 건지)을 직접 입력하는 과정이 중요하다. 같은 소재라도 취지문에 따라 완전히 다른 글이 나오니까.

### 작업 단위를 작게 쪼개기

하나 더 팁을 추가하면, 프로젝트 단위가 아니라 **작업 단위로 에이전트를 설계**하는 게 좋다.

처음부터 "YouTube 영상을 블로그로 변환하는 에이전트"를 만들려고 하면 너무 크다. 대신 이렇게 쪼개는 게 낫다:

- 자막 추출 에이전트 (= skill)
- 요약 에이전트
- 글감 제안 에이전트
- 초고 작성 에이전트 (= writer)
- 검토 에이전트 (= reviewer)

각각을 작은 단위로 만들고, 이걸 조합하는 오케스트레이터를 따로 두는 구조다. 마이크로서비스 아키텍처(?)랑 비슷한 느낌이라고 할까😏 `Claude Code`에서는 이런 멀티 에이전트 설계가 자연스럽게 가능하다.

작은 단위로 쪼개면 디버깅도 쉽고, 특정 에이전트만 교체하거나 개선하기도 편하다.

### 피드백 루프로 설계서 정교화하기

에이전트를 한 번 만들고 끝이 아니다. 오히려 **만든 후에 돌려보고, 안 되는 부분을 고치는 과정**이 진짜 핵심이다.

처음엔 좀 귀찮다😇 근데 내 경험상 이런 흐름이 반복된다:

1. 에이전트 실행
2. 예상과 다른 결과 발견
3. 설계서에서 빠진 부분 파악
4. 설계서 수정 (성공 기준 추가, 예외 처리 추가)
5. 다시 실행

이 사이클을 3~4번 돌리면 에이전트가 눈에 띄게 좋아진다. 실제로 내가 자막 추출 스크립트를 처음 돌렸을 때는 성공 기준이 "자막 파일이 생성되면 OK"였는데, 돌려보니 빈 파일이나 50자짜리 자막도 "성공"으로 통과하는 거다. 그래서 2회차에 "최소 500자 이상"이라는 기준을 추가했고, 3회차에는 자막 언어 우선순위(한국어 수동 → 자동 → 영어)까지 넣었다. 이런 식으로 설계서가 한 바퀴 돌 때마다 정교해진다.

에이전트가 "학습"하는 게 아니라, 설계서가 정교해지는 거다. 결국 **에이전트의 성장 = 설계서의 성장**이다.

그래서 처음부터 완벽한 설계서를 쓰려고 하지 않아도 된다. 일단 대략적으로 쓰고, 돌려보고, 고치면 된다. ~~완벽주의는 에이전트 개발에서도 적이다~~

---

## Claude Code로 에이전트를 직접 만들어봐야 하는 이유

여기서 좀 진지한 이야기를 하고 싶다.

에이전트를 잘 만드는 사람의 특징은 코딩을 잘하는 게 아니다. **자기가 하는 일을 언어로 잘 풀어내는 사람**이다.

"나는 블로그를 이렇게 쓴다"를 설명할 수 있는 사람. "이 작업의 성공 기준은 이거다"를 정의할 수 있는 사람. "이 단계에서 예외가 발생하면 이렇게 처리한다"를 미리 생각해둔 사람.

이걸 **업무 메타인지**라고 부르면 될 것 같다. 일을 하는 것뿐만 아니라, 일을 하는 과정 자체를 객관적으로 바라보고 구조화하는 능력.

그래서 나는 에이전트 설계서를 쓰는 과정 자체가 공부라고 생각한다. 내 업무 프로세스를 돌아보게 되고, 어디서 병목이 생기는지, 어디서 판단이 필요한지가 명확해진다.

이 글을 쓰면서 계속 하고 싶었던 말이 있다.

**에이전트, 한번 만들어보세요.**

읽는 것과 직접 해보는 건 완전히 달라요. 설계서를 쓰는 과정에서 자기 업무를 다시 보게 되고, 뭘 자동화할 수 있고 뭘 직접 해야 하는지가 명확해진다.

코딩을 몰라도 됩니다. 진짜로. `Claude Code`가 코드를 대신 짜준다. 내가 해야 할 건 **내 일을 잘 설명하는 것**뿐이다.

그리고 한번 만들어보면 AI를 바라보는 관점 자체가 바뀐다. "AI한테 질문하는 사람"에서 "AI 팀을 운영하는 사람"으로. 이 전환이 생각보다 크다🤩

좋은 에이전트를 만드는 건 코딩의 영역이 아니라 **업무 언어화의 영역**이다. 내가 하는 일을 구조화하고, 성공 기준을 정의하고, 예외를 미리 생각하는 것. 이게 에이전트 설계의 전부다.

아직 안 만들어봤다면, `Claude Code`로 작은 것부터 시작해보면 좋겠다. 반복적으로 하는 업무 하나를 골라서, 그걸 다른 사람에게 설명하듯이 문서로 적어보는 거다. 그게 바로 에이전트 설계서의 시작이니까😌

<br/>

💡**참고자료**
- [코딩 1도 모르는 직장인을 위한 Claude Code 시작 가이드](https://youtu.be/C6xlOsQFyOQ)
